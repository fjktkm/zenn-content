---
title: "フォントはベクター形式でも文字分類できるか？"
emoji: "🔢"
type: "tech"
topics: ["pytorch", "pytorchlightning", "機械学習", "font", "googlefonts"]
published: true
---

## 1. はじめに

以前の記事で，ベクターフォントの機械学習用ライブラリ TorchFont を紹介しました．

https://zenn.dev/fjktkm/articles/c674b6185076a8

TorchFont は Google Fonts などのフォントリポジトリからグリフのアウトライン情報を取得し，PyTorch の Dataset として扱えるようにするライブラリです．前回の記事ではライブラリの設計や使い方を紹介しましたが，実際にどのようなタスクに活用できるのかという点についてはあまり触れていませんでした．

フォントに関する機械学習では，従来はグリフをビットマップ画像に変換したうえで画像認識・生成の手法を適用するアプローチが主流です．しかし，フォントは本来ベクター形式で表現されるものであり，ビットマップ形式で生成しても実用的ではないという課題がありました．そこで，ベクターフォントのアウトラインを直接入力として扱うアプローチが近年注目されています．そのような流れをくむ研究に，Nagata et al. による TrueType Transformer（$\mathrm{T}^3$）があります．$\mathrm{T}^3$ はフォントのアウトラインの制御点列を Transformer に入力し，文字種やフォントスタイルの分類を行うモデルです．

https://arxiv.org/abs/2203.05338

https://github.com/uchidalab/TrueTypeTransformer

この記事では，TorchFont を使って $\mathrm{T}^3$ と同様の文字分類タスクに取り組みます．具体的には，Google Fonts に含まれるさまざまなフォントのアウトラインデータから，A 〜 Z の 26 文字を Transformer ベースのモデルで分類します．

https://github.com/torchfont/classification

## 2. データセット

### 2.1. データの読み込み

データセットには TorchFont の `GoogleFonts` クラスを使用します．`codepoint_filter` に A 〜 Z の Unicode コードポイントを指定することで，分類対象の文字を限定しています．

https://github.com/torchfont/classification/blob/3d7738f5641e1970d6c0a2db0db636879a285d0a/src/classification/lit_data_module.py#L51-L59

`LimitSequenceLength` は描画コマンドの系列長を最大 256 に制限する変換です．Rubik Pixels のように極端に長い系列を持つフォントが含まれているため，こうした制限が実用上必要になります．構築されたデータセットの詳細は次のとおりです．

|               項目 |      値 |
| -----------------: | ------: |
|       総サンプル数 | 216,857 |
|           文字種数 |      26 |
| フォントスタイル数 |   8,794 |

https://fonts.google.com/specimen/Rubik+Pixels

### 2.2. データ分割

データセットは学習・検証・テストの 3 つに分割します．比率は 90:5:5 です．再現性のためにシードを固定しています．

https://github.com/torchfont/classification/blob/3d7738f5641e1970d6c0a2db0db636879a285d0a/src/classification/lit_data_module.py#L73-L84

### 2.3. Collate 関数

TorchFont のデータセットは `(types, coords, style_label, content_label)` の 4 要素のタプルを返しますが，今回は文字の分類のみを行うため `style_label` は使用しません．描画コマンドの系列は可変長であるため，`collate_fn` でパディングを行って長さを揃えます．

https://github.com/torchfont/classification/blob/3d7738f5641e1970d6c0a2db0db636879a285d0a/src/classification/lit_data_module.py#L13-L24

## 3. モデル

### 3.1. 入力表現

フォントのアウトラインは描画コマンドの系列として表現されます．各コマンドはコマンド種別（`MoveTo`，`LineTo`，`CurveTo` など）と座標値を持っています．

これらをニューラルネットワークの入力とするために，コマンド種別を one-hot ベクトルに変換し，座標値と結合したうえで線形層により `d_model` 次元に射影します．

https://github.com/torchfont/classification/blob/3d7738f5641e1970d6c0a2db0db636879a285d0a/src/classification/module.py#L63-L82

ここではコマンド種別の one-hot ベクトルと連続的な座標値を結合して射影するという形式を取っています．テキストの埋め込みと画像の埋め込みの中間的なアプローチと言えるでしょう．

### 3.2. エンコーダ

エンコーダには HuggingFace Transformers の **ModernBERT** を採用しました．ModernBERT は従来の BERT に対して RoPE の採用など各種の工夫が加わったモデルです．

https://huggingface.co/docs/transformers/model_doc/modernbert

今回は事前学習済みの重みは使用せず，ランダム初期化から学習しています．モデルの設定は次のとおりです．

|               パラメータ |  値 |
| -----------------------: | --: |
|           隠れ層の次元数 | 128 |
|                     層数 |   3 |
|     アテンションヘッド数 |   4 |
| フィードフォワード次元数 | 256 |
|               最大系列長 | 512 |
|         ドロップアウト率 | 0.1 |

入力系列の先頭には学習可能な CLS トークンを付加します．エンコーダの出力のうち CLS トークンに対応する位置のベクトルを，系列全体の要約表現として利用します．パディングされた位置にはアテンションが及ばないように，`ops` がパディング値（0）でない位置をマスクとして渡しています．

### 3.3. 分類ヘッド

CLS トークンの出力に LayerNorm を適用したのち，Dropout と線形層を通して 26 クラスのロジットを出力します．

https://github.com/torchfont/classification/blob/3d7738f5641e1970d6c0a2db0db636879a285d0a/src/classification/module.py#L37-L41

全体のフォワードパスをまとめると次のようになります．

https://github.com/torchfont/classification/blob/3d7738f5641e1970d6c0a2db0db636879a285d0a/src/classification/module.py#L43-L60

## 4. 学習

### 4.1. 学習の設定

学習パイプラインは PyTorch Lightning で実装しています．損失関数にはクロスエントロピー損失を使用し，オプティマイザには AdamW を採用しています．バイアスと LayerNorm の重みに対しては weight decay を適用しないように，パラメータグループを分けています．

学習率スケジューラには Warmup + Cosine Annealing を使用しています．全ステップの 6% をウォームアップ期間として学習率を線形に増加させ，残りの期間でコサインカーブに従って減衰させます．

主要なハイパーパラメータは次のとおりです．

|         パラメータ |   値 |
| -----------------: | ---: |
|             学習率 | 1e-3 |
|       バッチサイズ |  256 |
|         エポック数 |    1 |
| ウォームアップ比率 |   6% |

学習と評価は次のように実行します．

https://github.com/torchfont/classification/blob/3d7738f5641e1970d6c0a2db0db636879a285d0a/src/classification/train.py#L10-L15

### 4.2. 学習時間

RTX 3060 Ti を使用した場合，学習時間は **約 90 秒** です．TorchFont がオンザフライで高速にグリフのアウトライン情報を取得するため，データの読み込みがボトルネックになることはありません．

なお，初回実行時のみ Google Fonts のリポジトリのクローンが行われるため，そのぶんの時間が別途かかります．

## 5. 実験結果

### 5.1. 全体の精度

テストデータ（10,842 サンプル）に対する accuracy は **89%** でした．マクロ平均の Precision，Recall，F1 スコアはいずれも約 0.89 です．エポック数を 1 としているなどサンプルコードとしての簡便さを優先していることを考えれば，十分高い精度が得られていると言えます．

### 5.2. 文字ごとの精度

各文字の Precision，Recall，F1 スコアは次のとおりです．

| 文字 | Precision | Recall |   F1 |
| :--: | --------: | -----: | ---: |
|  A   |      0.90 |   0.87 | 0.88 |
|  B   |      0.81 |   0.91 | 0.85 |
|  C   |      0.93 |   0.91 | 0.92 |
|  D   |      0.95 |   0.89 | 0.92 |
|  E   |      0.91 |   0.85 | 0.88 |
|  F   |      0.94 |   0.91 | 0.93 |
|  G   |      0.91 |   0.91 | 0.91 |
|  H   |      0.88 |   0.82 | 0.85 |
|  I   |      0.89 |   0.86 | 0.88 |
|  J   |      0.89 |   0.93 | 0.91 |
|  K   |      0.90 |   0.80 | 0.85 |
|  L   |      0.90 |   0.95 | 0.92 |
|  M   |      0.79 |   0.85 | 0.82 |
|  N   |      0.85 |   0.80 | 0.83 |
|  O   |      0.94 |   0.90 | 0.92 |
|  P   |      0.78 |   0.90 | 0.84 |
|  Q   |      0.85 |   0.95 | 0.90 |
|  R   |      0.88 |   0.90 | 0.89 |
|  S   |      0.92 |   0.89 | 0.91 |
|  T   |      0.89 |   0.91 | 0.90 |
|  U   |      0.93 |   0.89 | 0.91 |
|  V   |      0.92 |   0.92 | 0.92 |
|  W   |      0.91 |   0.88 | 0.90 |
|  X   |      0.86 |   0.86 | 0.86 |
|  Y   |      0.92 |   0.91 | 0.91 |
|  Z   |      0.87 |   0.90 | 0.89 |

F1 スコアがもっとも高い文字は F の 0.93，もっとも低い文字は M の 0.82 です．全体的に 0.82 〜 0.93 の範囲に収まっており，バランスの取れた分類結果と言えます．

### 5.3. 混同行列

テストデータに対する混同行列は次のとおりです．

![混同行列](/images/2ee64f88276068/test_confusion_matrix.png)

混同行列を見ると，いくつかの興味深い誤分類パターンが確認できます．特に目立つものを挙げると次のとおりです．

| 真のラベル | 予測ラベル | 誤分類回数 |
| :--------: | :--------: | ---------: |
|     N      |     M      |         27 |
|     K      |     X      |         27 |
|     H      |     M      |         15 |
|     F      |     P      |         15 |
|     W      |     M      |         11 |
|     I      |     Z      |         11 |

**N と M** はどちらも縦線と斜線の組み合わせで構成されており，アウトライン上の構造が類似しています．**K と X** についても交差する斜線という共通の構造を持っており，描画コマンド列として見たときに類似しやすいことが推察されます．**H と M** や **F と P** も同様に，縦線を主体とした構造を共有しています．

こうした誤分類パターンはいずれも形状が類似した文字同士の間で発生しており，モデルが文字のアウトライン構造に基づいて分類を行っていることが示唆されます．

## 6. 考察

### 6.1. ベクター形式の可能性

1 エポックの学習で 89% の精度が得られたことは，ベクターフォントのアウトライン情報が文字の構造的特徴を効果的に保持していることを示しています．ビットマップ画像でなくても文字認識が可能であるというのは，ベクター形式でフォントの機械学習を行う上で重要な知見だといえるでしょう．

### 6.2. データセットのノイズ

Google Fonts にはバーコードフォントや波形フォントなど，特殊用途のフォントも含まれています．こうしたフォントではアルファベットのコードポイントに対して本来の文字とはまったく異なるグリフが割り当てられているため，分類モデルにとってはノイズとなります．そうしたノイズが含まれたデータセットにおいて 89% の精度が得られていることを考えると，通常のフォントに対してはそれなりによく分類できていると言えるでしょう．

### 6.3. 今後の展望

今回の検証はモデルが比較的小規模でかつエポック数も最低限です．これは TorchFont のサンプルプロジェクトとしての位置づけを考慮してのことであり，もうすこし大きなモデルにしたりエポック数を増やしたりすることで，まだまだ精度の改善が見込めるでしょう．

また，今回は A 〜 Z の 26 文字のみを対象としましたが，TorchFont は日本語を含む多言語のフォントにも対応しています．対象文字数を増やした場合にどのように分類性能が変化するかも興味深い検証対象です．文字種を拡大する場合は，距離学習などの方向性も考えられます．

さらに，今回は文字種の分類（`content_label`）のみを行いましたが，TorchFont のデータセットにはフォントスタイルのラベル（`style_label`）も含まれています．スタイルの分類や，コンテンツとスタイルの両方を考慮した学習など，より発展的なタスクへの応用も考えられます．

## 7. おわりに

この記事では，TorchFont を使って Google Fonts のグリフアウトラインから A 〜 Z の文字分類を行いました．ModernBERT ベースの Transformer を用いて 1 エポックの学習で 89% の精度を達成できました．混同行列の分析からは，N と M や K と X のように形状が類似した文字同士が混同されやすいことが確認でき，モデルが文字のアウトライン構造を適切に捉えていることが示唆されました．

TorchFont を用いることで，フォントのグリフデータを使った機械学習パイプラインを手軽に構築できることが実感できたと思います．今回は分類タスクを取り上げましたが，ほかにも様々なタスクへの応用が考えられます．ぜひ TorchFont を使ってみてください．

それはそうと，ベクター形式に基づく文字分類ってなにか実用的なアプリケーションってあるんですかね？ベクターデータが残ってるならたぶん文字コードの情報も残っていそうな気がします．なにか面白いアイデアがあればぜひ教えてください．

## ソースコードの公開状況

この記事で紹介した分類プロジェクトのソースコードは以下のリポジトリで公開しています．

https://github.com/torchfont/classification

TorchFont 本体のソースコードは以下のリポジトリで公開しています．

https://github.com/torchfont/torchfont
